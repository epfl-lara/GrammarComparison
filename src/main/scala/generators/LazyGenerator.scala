//The following uses an incremental cantor function for sequential enumeration
/*package generators

import grammar._
import scala.collection.mutable.ListBuffer
import scala.collection.mutable.{ Map => MutableMap, Set => MutableSet }
import CFGrammar._
import grammar.utils._
import scala.annotation.tailrec

object LazyGenerator {
  sealed abstract class FailureReason
  object NotEnoughWords extends FailureReason
  object IndexOverFlowed extends FailureReason
  object NoFailure extends FailureReason
}
*//**
 * grammar - the grammar should not to have any epsilon productions (except from the
 * start symbol
 * maxWords - number of strings to be generated
 * debug - prints messages that help in debugging when set to true
 *//*
class LazyGenerator(inG: Grammar)(implicit opctx: GlobalContext) {
  import LazyGenerator._

  type Word = List[Terminal]
  type Words = List[Word]
  type Context = List[Nonterminal]

  //remove unproductive rules and reduce arity
  private val grammar = CNFConverter.removeUnproductiveRules(reduceArity(inG))
  private val basecases = RandomAccessGeneratorUtil.basecaseOfNonterminals(grammar)

  def nontermsInRightSide(rule: Rule): List[Nonterminal] = {
    rule.rightSide.collect { case nt: Nonterminal => nt }
  }

  def reduceArity(inG: Grammar): Grammar = {
    Grammar(inG.start, inG.rules.flatMap(reduceArityOfRule))
  }

  def reduceArityOfRule(rule: Rule): List[Rule] = {
    if (nontermsInRightSide(rule).size > 2) {
      val firstIndex = rule.rightSide.indexWhere(_.isInstanceOf[Nonterminal])
      val secondIndex = rule.rightSide.indexWhere(_.isInstanceOf[Nonterminal], firstIndex + 1)
      val newSym = Nonterminal(Util.freshName())
      val newRSide = rule.rightSide.take(secondIndex) :+ newSym
      val newRule = Rule(rule.leftSide, newRSide)
      val rest = rule.rightSide.drop(secondIndex)
      val otherRules = reduceArityOfRule(Rule(newSym, rest))
      newRule +: otherRules
    } else
      List(rule)
  }
  //
  //  private val noterminalRules = {
  //    assert(grammar.rules.forall(r => nontermsInRightSide(r).size <= 2))
  //    grammar.rules.groupBy(_.leftSide)
  //  }

  //a set of words generated by each non terminal
  private var yields = grammar.nonTerminals.map(_ -> ListBuffer[Word]()).toMap
  private var ruleIndices = {
    val mmap = MutableMap[Nonterminal, List[Int]]()
    grammar.nontermToRules.foreach {
      case (nt, rules) => mmap += (nt -> List.fill(rules.size)(-1))
    }
    mmap
  }
  //bounds on the maximum possible index of the nonterminals. 
  //identified dynamically
  private var nontermBounds = Map[Nonterminal, Int]()

  *//**
   * A mapping from rules to its yields and also the list of indices for each nonterminal
   * such that index i of a nonterminal 'nt' points to the word yields(nt)(i)
   *//*
  private var ruleYields = grammar.rules.map(_ -> ListBuffer[Word]()).toMap
  private var nontermIndices = {
    val mmap = MutableMap[Rule, List[Int]]()
    grammar.rules.foreach(rule => mmap += (rule -> List.fill(nontermsInRightSide(rule).size)(-1)))
    mmap
  }

  *//**
   * Increments index pair as per a diagonal order (cantor order)
   * Also handles bounded structure enumeration
   *//*
  def nextIndexPair(x: Int, y: Int, xbound: Option[Int], ybound: Option[Int]): List[Int] = {
    //require(x >= 0 && y >= 0)      
    val nextpair = if (x == 0 || (ybound == Some(y))) {
      //if 'x' is zero or 'y' has reached its upper bound, we go the other extreme
      val newx = x + y + 1
      xbound match {
        case Some(b) if newx > b =>
          val newy = newx - b
          if (!ybound.isDefined || ybound.get >= newy) //checking bounds for 'newy'
            List(b, newy)
          else
            //we have exhausted the enumeration of all points inside the closed space
            //so, returning the old indices
            List(x, y)
        case _ => List(newx, 0)
      }
    } else {
      //we decrement 'x' and increment'y' until 'x' becomes zero or 'y' reaches an upper bound        
      List(x - 1, y + 1)
    }
    nextpair
  }

  def nextIndex(indices: List[Int], bounds: List[Option[Int]]): List[Int] = indices match {
    case List() => List()
    case List(x) =>
      bounds(0) match {
        case Some(b) if x >= b => List(b)
        case _ => List(x + 1) //no bounds here or within bounds satisfied
      }
    case List(-1, -1) => List(0, 0)
    case List(x, y) =>
      nextIndexPair(x, y, bounds(0), bounds(1))
  }

  //a three valued result of querying an element at an index 
  sealed abstract class LookupResult
  object NoElementAtIndex extends LookupResult
  case class Element(word: List[Terminal]) extends LookupResult

  @tailrec final def getWordAtIndex(rule: Rule, index: Int): LookupResult = {

    if (opctx.debugGenerator > 1)
      println("Rule: " + rule + " Index: " + index)
    val words = ruleYields(rule)
    if (index < words.size) {
      Element(words(index))
    } else
      rule match {
        case Rule(_, rhs) if nontermsInRightSide(rule).isEmpty =>
          if (index > 0)
            NoElementAtIndex
          else
            Element(rhs.map(_.asInstanceOf[Terminal]))
        case Rule(lhs, rhs) =>
          val nonterms = nontermsInRightSide(rule)
          val currentIndices = nontermIndices(rule)
          val nextIndices = nextIndex(currentIndices, nonterms.map(nontermBounds.get _))
          val nontermIndexPairs = (nonterms zip nextIndices)
          //println("Next Indices: "+nontermIndexPairs)

          if (nextIndices == currentIndices)
            //no more elements to enumerate
            NoElementAtIndex
          else {
            val words = nontermIndexPairs.map {
              case (nt, i) =>
                val w = getWordAtIndex(nt, i)
                if (opctx.debugGenerator > 1)
                  println(nt + "(" + i + ")" + "=" + w)
                w
            }
            if (words.forall(_.isInstanceOf[Element])) {
              var i = -1
              val newword = rhs.foldLeft(List[Terminal]()) {
                case (acc, t: Terminal) => acc :+ t
                case (acc, nt: Nonterminal) =>
                  i += 1
                  acc ++ words(i).asInstanceOf[Element].word
                case (_, other) =>
                  throw new IllegalStateException("Invalid Symbol in rhs: " + other)
              }
              ruleYields(rule) += newword
              nontermIndices(rule) = nextIndices
              getWordAtIndex(rule, index)
            } else {
              //Here, we are hitting a bound for some nonterminals,
              //so retry to get the correct next indices
              getWordAtIndex(rule, index)
            }
          }
      }
  }

  *//**
   * Returns the word belonging to the non-terminal at the specified index.
   * The index should be within 0 and n where 'n' is the size
   * of the current set of words
   *//*
  @tailrec final def getWordAtIndex(nt: Nonterminal, index: Int): LookupResult = {

    if (opctx.debugGenerator > 1)
      println("Nt: " + nt + " index: " + index)

    val words = yields(nt)
    if (index < words.size) {
      Element(words(index))
    } else {
      val rules = grammar.nontermToRules(nt)

      val (newIndices, newwords) = if (index == 0) {
        //just use the base case
        val baserule = basecases(nt)
        val Element(word) = getWordAtIndex(baserule, index) //here, nt is production, so it must have a word at index '0'
        val newIndices = (rules zip ruleIndices(nt)).map {
          case (rl, i) =>
            if (rl == baserule)
              i + 1
            else i
        }
        (newIndices, List(word))
      } else {
        //get the yield of each of the 'rules' for the next unprocessed index
        var words = ListBuffer[Word]()
        val indices = (rules zip ruleIndices(nt)).foldLeft(List[Int]()) {
          case (acc, (rule, i)) =>
            getWordAtIndex(rule, i + 1) match {
              case Element(w) =>
                words += w
                acc :+ (i + 1)
              case _ =>
                //here, the rule has been exhausted, it is no longer usable                
                acc :+ i
            }
        }
        (indices, words)
      }
      //update the indices
      ruleIndices(nt) = newIndices
      if (!newwords.isEmpty) {
        val sortedWords = newwords.sorted(Ordering.by((w: Word) => w.size))
        //val sortedWords = newwords
        //add these new words to the yields(nt)
        yields(nt) ++= sortedWords

        //recursive invoke index again so that we get desired value
        getWordAtIndex(nt, index)
      } else {
        //here, we have reached a bound for every rule
        //Note we are not able to enumerate anything beyond the current list
        nontermBounds += (nt -> (words.size - 1))
        NoElementAtIndex
      }
    }
  }

  //some utility methods
  *//**
   * gets the word of the start symbol at the given index
   *//*
  def getWordAtIndex(index: Int): Option[Word] = {
    getWordAtIndex(grammar.start, index) match {
      case Element(w) => Some(w)
      case _ => None
    }
  }

  *//**
   * Returns the word of minimum length that can be generated by the
   * nonterminal
   *//*
  def getMinWord(nt: Nonterminal): Word = {
    //assuming that the minimum length word is always at index '0'
    val lookupRes = getWordAtIndex(nt, 0)
    lookupRes match {
      case Element(w) => w
      case _ =>
        throw new IllegalStateException("Cannot generate minimum word for nonterminal: " + nt)
    }
  }

  def getMinWord(nt: Nonterminal, prefix: Terminal) = {
    //assuming that the words are in increasing order
    var i = 0
    var found: Option[Word] = None
    while (!found.isDefined) {
      val lookupRes = getWordAtIndex(nt, i)
      i += 1
      lookupRes match {
        case Element(List()) => ; //ignore epsilon
        case Element(w) if w.head == prefix =>
          found = Some(w)
        case Element(_) => ;
        case _ =>
          throw new IllegalStateException("Cannot generate minimum word for nonterminal: " + nt + " with prefix " + prefix)
      }
    }
    found.get
  }

  *//**
   * Generates maxNow unique words for a nonterminal.
   * It enumerates words upto the given maxIndex.
   * If it is not possible to enumerate enough words provides a reason for that
   *//*
  def genWordsForNonterminal(nt: Nonterminal, maxNow: Int): (List[Word], FailureReason) = {
    val maxIndex = opctx.maxIndexForGeneration
    //using mutable collection for efficiency    
    var words = scala.collection.mutable.LinkedHashSet[Word]()
    var index = 0
    var break = false
    while (!break && words.size < maxNow && index <= maxIndex) {
      val lookupRes = getWordAtIndex(nt, index)
      lookupRes match {
        case Element(w) => words += w
        case _ => break = true
      }
      index += 1
    }
    val reason = if (index > maxIndex) IndexOverFlowed
    else if (words.size < maxNow) NotEnoughWords
    else NoFailure
    (words.toList, reason)
  }

  def genWords(maxNow: Int): (List[Word], FailureReason) = {
    genWordsForNonterminal(grammar.start, maxNow)
  }

  *//**
   * Generate a random word form a set words of size 'min' to 'max'
   *//*
  def genRandomWord(minsize: Int, maxsize: Int): Option[Word] = {
    val maxIndex = opctx.maxIndexForGeneration
    var words = Set[Word]()
    var index = 0
    var break = false
    while (!break && index <= maxIndex) {
      val lookupRes = getWordAtIndex(inG.start, index)
      lookupRes match {
        case Element(w) if (w.size < minsize) =>
          ; //continue
        case Element(w) if (w.size <= maxsize) =>
          words += w
        case _ =>
          break = true
      }
      index += 1
    }
    if (words.isEmpty)
      None
    else {
      //generate a random number from words
      val randomIndex = scala.util.Random.nextInt(words.size)
      Some(words.toList(randomIndex))
    }
  }

  *//**
   * Returns a list of words (without duplicates) generated by the sentential form
   * @param maxNow maximum number of words
   *//*
  def genWordsForSententialForm(sform: List[Symbol], maxNOW: Int): List[Word] = {
    //generate 'maxNOW' unique strings for each symbol in sform and pick
    // the first 'maxNow' words of the cartesian product    
    val listOfWords = sform.map(symb => symb match {
      case t: Terminal => List(List(t))
      case nt: Nonterminal =>
        //generate maxNow unique words 
        val ntwords = genWordsForNonterminal(nt, maxNOW)._1
        ntwords
    })
    if (listOfWords.isEmpty) {
      //nothing can be generated
      List()
    } else {
      val head :: tail = listOfWords
      val words = tail.foldLeft(head)((acc, words) => {
        val product = Util.cartesianProduct(acc, words, Some(maxNOW))
        product.map { case (w1, w2) => w1 ++ w2 }
      })
      words
    }
  }
}*/